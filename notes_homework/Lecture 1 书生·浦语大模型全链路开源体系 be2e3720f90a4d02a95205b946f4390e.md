# Lecture 1: 书生·浦语大模型全链路开源体系

## 学习前的疑问

- 大模型的评判标准有哪些？
- 大模型当前主要往哪些方面去优化？
- 大模型全链路架构层面的模块组成部分有哪些？
- 对于大模型的生态链主要要关注哪些部分？

## 学习后的疑问

- 大模型中的 token 是什么意思

![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled.png)

- Loss 图
    
    ![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled%201.png)
    
- 性能成长曲线
    
    ![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled%202.png)
    
- 各个评测集的侧重点
- 为什么大模型的数学运算在不借助外部工具的情况下都不太好

## 主讲人

陈恺（上海人工智能实验室 青年科学家）

## 学习笔记

- 人工智能技术不断发展，由当初的专用模型（针对特定任务，一个模型解决一个问题）进化到了通用大模型（一个模型对应多个任务，多种模态），大家相关大模型是走向通用人工智能的重要途径
- 语言模型的演进
    - 1990s: 以 n-gram model 为代表的基于统计概率估计的模型，辅助特定任务
    - 2013: 以 word2vec 为代表的向量化表示词的神经网诺模型，能完成特定的 NLP 任务
    - 2018: 以 ELMO, BERT, GPT-1/2 为代表的，基于上下文表示的加入预训练(pre-training)和模型微调(fine-tuning)的深度神经网络模型，能够解决多个 NLP 任务
    - 2020: 以 GPT-3/4, Claude 为代表的基于提示词(prompt based completion)的大模型，能够完成多个现实任务
    - 大模型发展时间线
        
        ![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled%203.png)
        
- 书生浦语大模型的开源历程
    - 千亿参数大模型发布 （2023.6）
    - 模型全面升级，支持8K语境，26种语言，全面开源，免费商用的：(2023.7)
        - InternLM-7B 模型、全链条开源工具体系
    - 多模态预训练语料库开源发布（2023.8）
    - 升级对话模型，发布开源智能体框架 Lagent，支持从语言模型到智能体升级转换（2023.8）
    - 模型参数量升级至123B（2023.8）
    - 增强版 InternalLM-20B 开源工具链全线升级
    - InternLM2 开源(2024.1)
    
    协议、模型大小、智能体应用，全链路工具链是任何实用大模型都应该具备的，也是开发者需要关心的。
    
- InternLM2
    - 核心理念：回顾语言建模的本质，即通过更高质量的语料和更高的信息密度，实现模型能力的提升
    - 模型规格
        - 7B 轻量模型与 20B 更支持复杂场景的模型
        - InternLM2-Base: 高质量且可塑性强的模型基座
        - InternLM2: 基于 base，在多个能力方面进行加强且保留了很好的通用语言能力，在大部分应用中可将其考虑作为基座
        - InternLM2-Chat: 在 base 基础上，经过 SFT(supervised fine-tuning)和 RLHF(reinforcement learning and human feedback)，面向对话交互进行了优化，能够遵循指令、共情聊天和调用工具
    - 新一代的数据清洗过滤技术：
        - 多维度数据价值评估：基于文本质量、信息质量和信息密度对数据价值进行数据机制综合评估
        - 高质量语料驱动的数据富集：利用高质量语料特征从物理世界、互联网和语料库中进一步富集更多类似语料
        - 有针对性地进行数据补齐：补充语调，重点加强世界知识、数理、代码等核心能力
    - InternLM2 亮点：
        - 超长上下文（20w token）
        - 综合性能全面提升（推理、数学、代码）
        - 优秀对话和创作体验（准确指令跟随，丰富的结构化创作）
        - 工具调用能力升级（可靠支持多轮调用工具和复杂智能体搭建）
        - 突出的数理能力和实用数据分析功能
- 从模型到应用的典型流程
    
    ![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled%204.png)
    
- 书生浦语全链条开源体系
    - 数据：
        - 简介：2TB 数据，覆盖多种模态与任务
        - 书生万卷1.0：符合主流中国价值观的中文语料，进行了多模态融合，精细化处理
        - 书生万卷cc：安全、信息密度更高的英文语料
    - 预训练
        - 简介：并行训练，机制优化，速度达到 3600 tokens/sec/gpu
        - 高可扩展：支持从 8 卡到千卡训练
        - 利用 Hybrid zero 进行性能优化，加速 50%
        - 兼容主流技术生态，支持各类轻量化技术
        - 支持各规格语言模型，修改配置即可训练
    - 微调
        - 简介：支持全参数微调，支持 LoRA 等低成本微调
        - 增量续训
            - 学到垂直领域的知识
        - 有监督微调
            - 让模型理解各种指令和注入少量领域知识
        - 高效微调框架 XTuner
            - 支持多种微调算法
            - 适配多种开源模型和数据集
            - 自动优化加速
            - 适配多种硬件
            - 可以帮开发者简化数据格式
    - 部署
        - 简介：全链路部署，性能领先，每秒生成 2000+ tokens
        - 技术挑战
            - 如何解决巨大的存储问题，尤其是如何部署在低存储设备上
            - 如何加速 token 生成速度
            - 如何有效管理和利用内存
            - 如何提高系统吞吐量
        - 部署方案
            - 模型并行
            - 低比特量化
            - attention 优化
            - 计算和访存优化
            - Continuous batch
        - LMDeploy
            
            ![Untitled](Lecture%201%20%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%20be2e3720f90a4d02a95205b946f4390e/Untitled%205.png)
            
    - 评测
        - 简介：全方位评测，性能可复现；100 套评测集，50w 道题目
        - 思南大模型评测体系
            - 包括学习、语言、知识、理解和推理
            - CompassRank: 中立全面的性能榜单
            - CompassKit 大模型评测全栈工具链
                - VLMEvalKit 多模态评测工具
                - code-evaluator 代码评测工具
                - MixtralKit MoE 模型入门工具
            - CompassHub 开源开放的高质量评测基准社区
            - 更加准确的循环评测（对选项进行轮换，避免模型乱猜）
            - 基于评测的一些洞见
                - 模型的区分主要在复杂推理的表现上，能力与模型大小关联性高，且这方面是当前大模型的短板
                - 国内模型在中文场景中更具性能优势
                - 模型的能力还有很大的提升空间
    - 应用
        - 简介：支持多种智能体，支持代码解释器等多种工具
        - 多模态智能体工具箱 AgentoLego
            - 提供了大量视觉和多模态相关领域的前沿算法功能
            - 支持主流智能体系统，如 LangChain, Transformers Agent, lagent 等
            - 灵活的多模态工具调用
            - 一键式部署

## 关键词

- token
- 智能体 agent
- 模型规格
- 数据清洗过滤
- 预训练
- 微调
- 增量微调
- 有监督微调